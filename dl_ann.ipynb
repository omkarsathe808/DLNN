{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1e83ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0cba02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.20.0-cp312-cp312-win_amd64.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\genai\\venv-genai\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\genai\\venv-genai\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\genai\\venv-genai\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\genai\\venv-genai\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\genai\\venv-genai\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\genai\\venv-genai\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\genai\\venv-genai\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\genai\\venv-genai\\lib\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\genai\\venv-genai\\lib\\site-packages (from tensorflow) (6.32.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\genai\\venv-genai\\lib\\site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in c:\\genai\\venv-genai\\lib\\site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\genai\\venv-genai\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\genai\\venv-genai\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\genai\\venv-genai\\lib\\site-packages (from tensorflow) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\genai\\venv-genai\\lib\\site-packages (from tensorflow) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\genai\\venv-genai\\lib\\site-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\genai\\venv-genai\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Using cached keras-3.11.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\genai\\venv-genai\\lib\\site-packages (from tensorflow) (2.2.5)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\genai\\venv-genai\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\genai\\venv-genai\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\genai\\venv-genai\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Collecting rich (from keras>=3.10.0->tensorflow)\n",
      "  Using cached rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: namex in c:\\genai\\venv-genai\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\genai\\venv-genai\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\genai\\venv-genai\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\genai\\venv-genai\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\genai\\venv-genai\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\genai\\venv-genai\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\genai\\venv-genai\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.8.2)\n",
      "Requirement already satisfied: pillow in c:\\genai\\venv-genai\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\genai\\venv-genai\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\genai\\venv-genai\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\genai\\venv-genai\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.10.0->tensorflow)\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\genai\\venv-genai\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\genai\\venv-genai\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Using cached tensorflow-2.20.0-cp312-cp312-win_amd64.whl (331.9 MB)\n",
      "Using cached keras-3.11.3-py3-none-any.whl (1.4 MB)\n",
      "Using cached rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Installing collected packages: markdown-it-py, rich, keras, tensorflow\n",
      "Successfully installed keras-3.11.3 markdown-it-py-4.0.0 rich-14.1.0 tensorflow-2.20.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4243713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a551147",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('binary_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d08245f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_1</th>\n",
       "      <th>input_2</th>\n",
       "      <th>input_3</th>\n",
       "      <th>input_4</th>\n",
       "      <th>input_5</th>\n",
       "      <th>input_6</th>\n",
       "      <th>input_7</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.496714</td>\n",
       "      <td>-0.138264</td>\n",
       "      <td>0.647689</td>\n",
       "      <td>1.523030</td>\n",
       "      <td>-0.234153</td>\n",
       "      <td>-0.234137</td>\n",
       "      <td>1.579213</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.767435</td>\n",
       "      <td>-0.469474</td>\n",
       "      <td>0.542560</td>\n",
       "      <td>-0.463418</td>\n",
       "      <td>-0.465730</td>\n",
       "      <td>0.241962</td>\n",
       "      <td>-1.913280</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.724918</td>\n",
       "      <td>-0.562288</td>\n",
       "      <td>-1.012831</td>\n",
       "      <td>0.314247</td>\n",
       "      <td>-0.908024</td>\n",
       "      <td>-1.412304</td>\n",
       "      <td>1.465649</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    input_1   input_2   input_3   input_4   input_5   input_6   input_7  \\\n",
       "0  0.496714 -0.138264  0.647689  1.523030 -0.234153 -0.234137  1.579213   \n",
       "1  0.767435 -0.469474  0.542560 -0.463418 -0.465730  0.241962 -1.913280   \n",
       "2 -1.724918 -0.562288 -1.012831  0.314247 -0.908024 -1.412304  1.465649   \n",
       "\n",
       "   output  \n",
       "0     1.0  \n",
       "1     0.0  \n",
       "2     0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adc970fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 8 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   input_1  2000 non-null   float64\n",
      " 1   input_2  2000 non-null   float64\n",
      " 2   input_3  2000 non-null   float64\n",
      " 3   input_4  2000 non-null   float64\n",
      " 4   input_5  2000 non-null   float64\n",
      " 5   input_6  2000 non-null   float64\n",
      " 6   input_7  2000 non-null   float64\n",
      " 7   output   2000 non-null   float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 125.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a1dc4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74983d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_1</th>\n",
       "      <th>input_2</th>\n",
       "      <th>input_3</th>\n",
       "      <th>input_4</th>\n",
       "      <th>input_5</th>\n",
       "      <th>input_6</th>\n",
       "      <th>input_7</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.011210</td>\n",
       "      <td>0.006434</td>\n",
       "      <td>0.017266</td>\n",
       "      <td>-0.019354</td>\n",
       "      <td>-0.045741</td>\n",
       "      <td>0.036013</td>\n",
       "      <td>0.016710</td>\n",
       "      <td>0.504500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.985840</td>\n",
       "      <td>1.010564</td>\n",
       "      <td>1.007568</td>\n",
       "      <td>1.012431</td>\n",
       "      <td>1.012373</td>\n",
       "      <td>1.013294</td>\n",
       "      <td>0.966612</td>\n",
       "      <td>0.500105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.221016</td>\n",
       "      <td>-3.375579</td>\n",
       "      <td>-3.688365</td>\n",
       "      <td>-3.836656</td>\n",
       "      <td>-3.241514</td>\n",
       "      <td>-3.922400</td>\n",
       "      <td>-2.908661</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.667445</td>\n",
       "      <td>-0.657998</td>\n",
       "      <td>-0.655159</td>\n",
       "      <td>-0.733670</td>\n",
       "      <td>-0.704931</td>\n",
       "      <td>-0.627159</td>\n",
       "      <td>-0.636369</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.008332</td>\n",
       "      <td>0.006202</td>\n",
       "      <td>0.029813</td>\n",
       "      <td>-0.039674</td>\n",
       "      <td>-0.060248</td>\n",
       "      <td>0.045498</td>\n",
       "      <td>0.011523</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.639939</td>\n",
       "      <td>0.685866</td>\n",
       "      <td>0.700306</td>\n",
       "      <td>0.654006</td>\n",
       "      <td>0.634214</td>\n",
       "      <td>0.702565</td>\n",
       "      <td>0.655533</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.098299</td>\n",
       "      <td>2.985259</td>\n",
       "      <td>3.428910</td>\n",
       "      <td>3.529055</td>\n",
       "      <td>3.926238</td>\n",
       "      <td>3.377768</td>\n",
       "      <td>3.852731</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           input_1      input_2      input_3      input_4      input_5  \\\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean     -0.011210     0.006434     0.017266    -0.019354    -0.045741   \n",
       "std       0.985840     1.010564     1.007568     1.012431     1.012373   \n",
       "min      -3.221016    -3.375579    -3.688365    -3.836656    -3.241514   \n",
       "25%      -0.667445    -0.657998    -0.655159    -0.733670    -0.704931   \n",
       "50%       0.008332     0.006202     0.029813    -0.039674    -0.060248   \n",
       "75%       0.639939     0.685866     0.700306     0.654006     0.634214   \n",
       "max       3.098299     2.985259     3.428910     3.529055     3.926238   \n",
       "\n",
       "           input_6      input_7       output  \n",
       "count  2000.000000  2000.000000  2000.000000  \n",
       "mean      0.036013     0.016710     0.504500  \n",
       "std       1.013294     0.966612     0.500105  \n",
       "min      -3.922400    -2.908661     0.000000  \n",
       "25%      -0.627159    -0.636369     0.000000  \n",
       "50%       0.045498     0.011523     1.000000  \n",
       "75%       0.702565     0.655533     1.000000  \n",
       "max       3.377768     3.852731     1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ec16890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>input_1</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>-0.011210</td>\n",
       "      <td>0.985840</td>\n",
       "      <td>-3.221016</td>\n",
       "      <td>-0.667445</td>\n",
       "      <td>0.008332</td>\n",
       "      <td>0.639939</td>\n",
       "      <td>3.098299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>input_2</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.006434</td>\n",
       "      <td>1.010564</td>\n",
       "      <td>-3.375579</td>\n",
       "      <td>-0.657998</td>\n",
       "      <td>0.006202</td>\n",
       "      <td>0.685866</td>\n",
       "      <td>2.985259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>input_3</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.017266</td>\n",
       "      <td>1.007568</td>\n",
       "      <td>-3.688365</td>\n",
       "      <td>-0.655159</td>\n",
       "      <td>0.029813</td>\n",
       "      <td>0.700306</td>\n",
       "      <td>3.428910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>input_4</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>-0.019354</td>\n",
       "      <td>1.012431</td>\n",
       "      <td>-3.836656</td>\n",
       "      <td>-0.733670</td>\n",
       "      <td>-0.039674</td>\n",
       "      <td>0.654006</td>\n",
       "      <td>3.529055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>input_5</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>-0.045741</td>\n",
       "      <td>1.012373</td>\n",
       "      <td>-3.241514</td>\n",
       "      <td>-0.704931</td>\n",
       "      <td>-0.060248</td>\n",
       "      <td>0.634214</td>\n",
       "      <td>3.926238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>input_6</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.036013</td>\n",
       "      <td>1.013294</td>\n",
       "      <td>-3.922400</td>\n",
       "      <td>-0.627159</td>\n",
       "      <td>0.045498</td>\n",
       "      <td>0.702565</td>\n",
       "      <td>3.377768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>input_7</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.016710</td>\n",
       "      <td>0.966612</td>\n",
       "      <td>-2.908661</td>\n",
       "      <td>-0.636369</td>\n",
       "      <td>0.011523</td>\n",
       "      <td>0.655533</td>\n",
       "      <td>3.852731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>output</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.504500</td>\n",
       "      <td>0.500105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count      mean       std       min       25%       50%       75%  \\\n",
       "input_1  2000.0 -0.011210  0.985840 -3.221016 -0.667445  0.008332  0.639939   \n",
       "input_2  2000.0  0.006434  1.010564 -3.375579 -0.657998  0.006202  0.685866   \n",
       "input_3  2000.0  0.017266  1.007568 -3.688365 -0.655159  0.029813  0.700306   \n",
       "input_4  2000.0 -0.019354  1.012431 -3.836656 -0.733670 -0.039674  0.654006   \n",
       "input_5  2000.0 -0.045741  1.012373 -3.241514 -0.704931 -0.060248  0.634214   \n",
       "input_6  2000.0  0.036013  1.013294 -3.922400 -0.627159  0.045498  0.702565   \n",
       "input_7  2000.0  0.016710  0.966612 -2.908661 -0.636369  0.011523  0.655533   \n",
       "output   2000.0  0.504500  0.500105  0.000000  0.000000  1.000000  1.000000   \n",
       "\n",
       "              max  \n",
       "input_1  3.098299  \n",
       "input_2  2.985259  \n",
       "input_3  3.428910  \n",
       "input_4  3.529055  \n",
       "input_5  3.926238  \n",
       "input_6  3.377768  \n",
       "input_7  3.852731  \n",
       "output   1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95bb0cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "input_1    0\n",
       "input_2    0\n",
       "input_3    0\n",
       "input_4    0\n",
       "input_5    0\n",
       "input_6    0\n",
       "input_7    0\n",
       "output     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22e870c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "1995    False\n",
       "1996    False\n",
       "1997    False\n",
       "1998    False\n",
       "1999    False\n",
       "Length: 2000, dtype: bool"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1cd77e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09f94d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'X' contains all columns except for 'output'\n",
    "X = df.drop('output', axis=1)\n",
    "\n",
    "# 'y' contains only the 'output' column\n",
    "y = df['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aba248d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_1</th>\n",
       "      <th>input_2</th>\n",
       "      <th>input_3</th>\n",
       "      <th>input_4</th>\n",
       "      <th>input_5</th>\n",
       "      <th>input_6</th>\n",
       "      <th>input_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.496714</td>\n",
       "      <td>-0.138264</td>\n",
       "      <td>0.647689</td>\n",
       "      <td>1.523030</td>\n",
       "      <td>-0.234153</td>\n",
       "      <td>-0.234137</td>\n",
       "      <td>1.579213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.767435</td>\n",
       "      <td>-0.469474</td>\n",
       "      <td>0.542560</td>\n",
       "      <td>-0.463418</td>\n",
       "      <td>-0.465730</td>\n",
       "      <td>0.241962</td>\n",
       "      <td>-1.913280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.724918</td>\n",
       "      <td>-0.562288</td>\n",
       "      <td>-1.012831</td>\n",
       "      <td>0.314247</td>\n",
       "      <td>-0.908024</td>\n",
       "      <td>-1.412304</td>\n",
       "      <td>1.465649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.225776</td>\n",
       "      <td>0.067528</td>\n",
       "      <td>-1.424748</td>\n",
       "      <td>-0.544383</td>\n",
       "      <td>0.110923</td>\n",
       "      <td>-1.150994</td>\n",
       "      <td>0.375698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.600639</td>\n",
       "      <td>-0.291694</td>\n",
       "      <td>-0.601707</td>\n",
       "      <td>1.852278</td>\n",
       "      <td>-0.013497</td>\n",
       "      <td>-1.057711</td>\n",
       "      <td>0.822545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>-0.173815</td>\n",
       "      <td>0.995955</td>\n",
       "      <td>0.736227</td>\n",
       "      <td>-0.983103</td>\n",
       "      <td>-1.010591</td>\n",
       "      <td>-0.254374</td>\n",
       "      <td>0.736837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.148057</td>\n",
       "      <td>-0.643150</td>\n",
       "      <td>0.261519</td>\n",
       "      <td>-0.330811</td>\n",
       "      <td>0.880486</td>\n",
       "      <td>0.333058</td>\n",
       "      <td>-0.315278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.231519</td>\n",
       "      <td>1.315048</td>\n",
       "      <td>-0.569630</td>\n",
       "      <td>0.402657</td>\n",
       "      <td>-0.070460</td>\n",
       "      <td>0.426984</td>\n",
       "      <td>-0.654565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.110335</td>\n",
       "      <td>1.107823</td>\n",
       "      <td>-0.937007</td>\n",
       "      <td>-1.329405</td>\n",
       "      <td>-1.291456</td>\n",
       "      <td>-1.170663</td>\n",
       "      <td>0.595323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>-1.405860</td>\n",
       "      <td>-0.297895</td>\n",
       "      <td>0.618289</td>\n",
       "      <td>0.416659</td>\n",
       "      <td>-0.385559</td>\n",
       "      <td>0.190924</td>\n",
       "      <td>0.107145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       input_1   input_2   input_3   input_4   input_5   input_6   input_7\n",
       "0     0.496714 -0.138264  0.647689  1.523030 -0.234153 -0.234137  1.579213\n",
       "1     0.767435 -0.469474  0.542560 -0.463418 -0.465730  0.241962 -1.913280\n",
       "2    -1.724918 -0.562288 -1.012831  0.314247 -0.908024 -1.412304  1.465649\n",
       "3    -0.225776  0.067528 -1.424748 -0.544383  0.110923 -1.150994  0.375698\n",
       "4    -0.600639 -0.291694 -0.601707  1.852278 -0.013497 -1.057711  0.822545\n",
       "...        ...       ...       ...       ...       ...       ...       ...\n",
       "1995 -0.173815  0.995955  0.736227 -0.983103 -1.010591 -0.254374  0.736837\n",
       "1996  0.148057 -0.643150  0.261519 -0.330811  0.880486  0.333058 -0.315278\n",
       "1997  0.231519  1.315048 -0.569630  0.402657 -0.070460  0.426984 -0.654565\n",
       "1998  0.110335  1.107823 -0.937007 -1.329405 -1.291456 -1.170663  0.595323\n",
       "1999 -1.405860 -0.297895  0.618289  0.416659 -0.385559  0.190924  0.107145\n",
       "\n",
       "[2000 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b59aea9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       0.0\n",
       "4       1.0\n",
       "       ... \n",
       "1995    1.0\n",
       "1996    1.0\n",
       "1997    1.0\n",
       "1998    0.0\n",
       "1999    0.0\n",
       "Name: output, Length: 2000, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "907ce3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.iloc[:,0:-1]\n",
    "y= df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15eae319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_1</th>\n",
       "      <th>input_2</th>\n",
       "      <th>input_3</th>\n",
       "      <th>input_4</th>\n",
       "      <th>input_5</th>\n",
       "      <th>input_6</th>\n",
       "      <th>input_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.496714</td>\n",
       "      <td>-0.138264</td>\n",
       "      <td>0.647689</td>\n",
       "      <td>1.523030</td>\n",
       "      <td>-0.234153</td>\n",
       "      <td>-0.234137</td>\n",
       "      <td>1.579213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.767435</td>\n",
       "      <td>-0.469474</td>\n",
       "      <td>0.542560</td>\n",
       "      <td>-0.463418</td>\n",
       "      <td>-0.465730</td>\n",
       "      <td>0.241962</td>\n",
       "      <td>-1.913280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.724918</td>\n",
       "      <td>-0.562288</td>\n",
       "      <td>-1.012831</td>\n",
       "      <td>0.314247</td>\n",
       "      <td>-0.908024</td>\n",
       "      <td>-1.412304</td>\n",
       "      <td>1.465649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.225776</td>\n",
       "      <td>0.067528</td>\n",
       "      <td>-1.424748</td>\n",
       "      <td>-0.544383</td>\n",
       "      <td>0.110923</td>\n",
       "      <td>-1.150994</td>\n",
       "      <td>0.375698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.600639</td>\n",
       "      <td>-0.291694</td>\n",
       "      <td>-0.601707</td>\n",
       "      <td>1.852278</td>\n",
       "      <td>-0.013497</td>\n",
       "      <td>-1.057711</td>\n",
       "      <td>0.822545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    input_1   input_2   input_3   input_4   input_5   input_6   input_7\n",
       "0  0.496714 -0.138264  0.647689  1.523030 -0.234153 -0.234137  1.579213\n",
       "1  0.767435 -0.469474  0.542560 -0.463418 -0.465730  0.241962 -1.913280\n",
       "2 -1.724918 -0.562288 -1.012831  0.314247 -0.908024 -1.412304  1.465649\n",
       "3 -0.225776  0.067528 -1.424748 -0.544383  0.110923 -1.150994  0.375698\n",
       "4 -0.600639 -0.291694 -0.601707  1.852278 -0.013497 -1.057711  0.822545"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3bf8cefb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    0.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "Name: output, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f5b3183",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d662f45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc= StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5dca4b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.88171296,  0.31229879,  0.79977687, ...,  1.2166301 ,\n",
       "        -0.01250636,  0.03508656],\n",
       "       [ 0.4106209 , -0.03267114, -0.89642315, ..., -1.13295989,\n",
       "         1.14838849, -0.50228145],\n",
       "       [-0.18694097, -0.57740697, -0.28523484, ...,  1.42395623,\n",
       "        -0.63971559,  0.07732647],\n",
       "       ...,\n",
       "       [ 0.25546268,  0.38678617,  2.43734569, ..., -0.28303275,\n",
       "         0.09363827,  1.07761968],\n",
       "       [-0.10817496, -1.90411904, -0.95664478, ..., -2.67376728,\n",
       "         1.1481401 ,  0.51165485],\n",
       "       [ 1.29749779, -0.06522895,  0.12975408, ...,  1.18577221,\n",
       "        -1.65111788,  0.5767523 ]], shape=(1600, 7))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=sc.fit_transform(X_train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "088b9908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.15551846,  0.99475181, -0.18549756, ...,  0.16253762,\n",
       "         1.02441568,  0.80375679],\n",
       "       [ 2.38193209, -0.78732539, -1.36503441, ...,  0.74259226,\n",
       "        -0.24850278,  1.47024117],\n",
       "       [-0.30688516, -0.57780731,  0.84650587, ..., -0.15432125,\n",
       "         1.34905633, -0.24271779],\n",
       "       ...,\n",
       "       [-0.54130144, -1.92297251, -0.3330173 , ..., -0.82956279,\n",
       "        -1.51866793,  0.3706796 ],\n",
       "       [ 1.42356217, -0.10636679,  0.00925317, ...,  0.26068234,\n",
       "         0.9174261 ,  0.27087882],\n",
       "       [-0.17794699, -2.16537327,  0.16596034, ..., -1.42416288,\n",
       "        -0.59814396,  0.31405761]], shape=(400, 7))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=sc.transform(X_test)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d86aef95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21634ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier= Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2eda2c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\genAI\\venv-genAI\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(units= 5, kernel_initializer='he_uniform', activation='relu', input_dim=7))\n",
    "classifier.add(Dense(units= 5, kernel_initializer='he_uniform', activation='relu'))\n",
    "classifier.add(Dense(units=1, kernel_initializer='glorot_uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e844f3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31102f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6968 - loss: 0.6063 - val_accuracy: 0.7235 - val_loss: 0.5858\n",
      "Epoch 2/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7547 - loss: 0.5389 - val_accuracy: 0.7557 - val_loss: 0.5229\n",
      "Epoch 3/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7957 - loss: 0.4724 - val_accuracy: 0.7841 - val_loss: 0.4651\n",
      "Epoch 4/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8218 - loss: 0.4145 - val_accuracy: 0.8011 - val_loss: 0.4167\n",
      "Epoch 5/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8451 - loss: 0.3704 - val_accuracy: 0.8258 - val_loss: 0.3800\n",
      "Epoch 6/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8517 - loss: 0.3406 - val_accuracy: 0.8409 - val_loss: 0.3542\n",
      "Epoch 7/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8647 - loss: 0.3215 - val_accuracy: 0.8504 - val_loss: 0.3360\n",
      "Epoch 8/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8666 - loss: 0.3093 - val_accuracy: 0.8598 - val_loss: 0.3235\n",
      "Epoch 9/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8722 - loss: 0.3020 - val_accuracy: 0.8617 - val_loss: 0.3159\n",
      "Epoch 10/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8731 - loss: 0.2966 - val_accuracy: 0.8674 - val_loss: 0.3103\n",
      "Epoch 11/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8750 - loss: 0.2931 - val_accuracy: 0.8731 - val_loss: 0.3056\n",
      "Epoch 12/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8750 - loss: 0.2902 - val_accuracy: 0.8750 - val_loss: 0.3022\n",
      "Epoch 13/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8750 - loss: 0.2879 - val_accuracy: 0.8788 - val_loss: 0.3000\n",
      "Epoch 14/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8741 - loss: 0.2860 - val_accuracy: 0.8807 - val_loss: 0.2976\n",
      "Epoch 15/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8759 - loss: 0.2848 - val_accuracy: 0.8826 - val_loss: 0.2965\n",
      "Epoch 16/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8769 - loss: 0.2838 - val_accuracy: 0.8788 - val_loss: 0.2954\n",
      "Epoch 17/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8769 - loss: 0.2821 - val_accuracy: 0.8807 - val_loss: 0.2940\n",
      "Epoch 18/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8759 - loss: 0.2811 - val_accuracy: 0.8845 - val_loss: 0.2940\n",
      "Epoch 19/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8787 - loss: 0.2794 - val_accuracy: 0.8826 - val_loss: 0.2940\n",
      "Epoch 20/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8769 - loss: 0.2785 - val_accuracy: 0.8826 - val_loss: 0.2931\n",
      "Epoch 21/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8797 - loss: 0.2780 - val_accuracy: 0.8826 - val_loss: 0.2927\n",
      "Epoch 22/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8778 - loss: 0.2776 - val_accuracy: 0.8826 - val_loss: 0.2923\n",
      "Epoch 23/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8769 - loss: 0.2772 - val_accuracy: 0.8845 - val_loss: 0.2911\n",
      "Epoch 24/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8787 - loss: 0.2763 - val_accuracy: 0.8788 - val_loss: 0.2908\n",
      "Epoch 25/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8787 - loss: 0.2755 - val_accuracy: 0.8864 - val_loss: 0.2906\n",
      "Epoch 26/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8787 - loss: 0.2749 - val_accuracy: 0.8883 - val_loss: 0.2901\n",
      "Epoch 27/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8787 - loss: 0.2745 - val_accuracy: 0.8845 - val_loss: 0.2897\n",
      "Epoch 28/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8797 - loss: 0.2737 - val_accuracy: 0.8845 - val_loss: 0.2893\n",
      "Epoch 29/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8778 - loss: 0.2730 - val_accuracy: 0.8826 - val_loss: 0.2894\n",
      "Epoch 30/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8787 - loss: 0.2730 - val_accuracy: 0.8807 - val_loss: 0.2888\n",
      "Epoch 31/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8787 - loss: 0.2723 - val_accuracy: 0.8807 - val_loss: 0.2890\n",
      "Epoch 32/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8787 - loss: 0.2718 - val_accuracy: 0.8845 - val_loss: 0.2880\n",
      "Epoch 33/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8769 - loss: 0.2710 - val_accuracy: 0.8845 - val_loss: 0.2874\n",
      "Epoch 34/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8806 - loss: 0.2714 - val_accuracy: 0.8788 - val_loss: 0.2876\n",
      "Epoch 35/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8769 - loss: 0.2710 - val_accuracy: 0.8750 - val_loss: 0.2870\n",
      "Epoch 36/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8806 - loss: 0.2704 - val_accuracy: 0.8788 - val_loss: 0.2870\n",
      "Epoch 37/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8787 - loss: 0.2702 - val_accuracy: 0.8731 - val_loss: 0.2864\n",
      "Epoch 38/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8778 - loss: 0.2694 - val_accuracy: 0.8731 - val_loss: 0.2862\n",
      "Epoch 39/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8797 - loss: 0.2695 - val_accuracy: 0.8712 - val_loss: 0.2860\n",
      "Epoch 40/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8750 - loss: 0.2690 - val_accuracy: 0.8712 - val_loss: 0.2858\n",
      "Epoch 41/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8759 - loss: 0.2687 - val_accuracy: 0.8693 - val_loss: 0.2854\n",
      "Epoch 42/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8750 - loss: 0.2679 - val_accuracy: 0.8731 - val_loss: 0.2851\n",
      "Epoch 43/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8759 - loss: 0.2680 - val_accuracy: 0.8712 - val_loss: 0.2854\n",
      "Epoch 44/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8769 - loss: 0.2673 - val_accuracy: 0.8750 - val_loss: 0.2842\n",
      "Epoch 45/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8769 - loss: 0.2672 - val_accuracy: 0.8769 - val_loss: 0.2842\n",
      "Epoch 46/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8787 - loss: 0.2671 - val_accuracy: 0.8731 - val_loss: 0.2846\n",
      "Epoch 47/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8750 - loss: 0.2666 - val_accuracy: 0.8731 - val_loss: 0.2843\n",
      "Epoch 48/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8769 - loss: 0.2663 - val_accuracy: 0.8731 - val_loss: 0.2838\n",
      "Epoch 49/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8769 - loss: 0.2658 - val_accuracy: 0.8731 - val_loss: 0.2834\n",
      "Epoch 50/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8750 - loss: 0.2652 - val_accuracy: 0.8750 - val_loss: 0.2833\n",
      "Epoch 51/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8778 - loss: 0.2648 - val_accuracy: 0.8750 - val_loss: 0.2832\n",
      "Epoch 52/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8797 - loss: 0.2645 - val_accuracy: 0.8769 - val_loss: 0.2825\n",
      "Epoch 53/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8778 - loss: 0.2639 - val_accuracy: 0.8769 - val_loss: 0.2813\n",
      "Epoch 54/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8787 - loss: 0.2638 - val_accuracy: 0.8769 - val_loss: 0.2816\n",
      "Epoch 55/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8759 - loss: 0.2629 - val_accuracy: 0.8788 - val_loss: 0.2808\n",
      "Epoch 56/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8769 - loss: 0.2630 - val_accuracy: 0.8769 - val_loss: 0.2808\n",
      "Epoch 57/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8769 - loss: 0.2629 - val_accuracy: 0.8788 - val_loss: 0.2806\n",
      "Epoch 58/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8778 - loss: 0.2622 - val_accuracy: 0.8807 - val_loss: 0.2805\n",
      "Epoch 59/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8778 - loss: 0.2620 - val_accuracy: 0.8788 - val_loss: 0.2811\n",
      "Epoch 60/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8769 - loss: 0.2616 - val_accuracy: 0.8788 - val_loss: 0.2810\n",
      "Epoch 61/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8769 - loss: 0.2613 - val_accuracy: 0.8807 - val_loss: 0.2800\n",
      "Epoch 62/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8778 - loss: 0.2617 - val_accuracy: 0.8788 - val_loss: 0.2805\n",
      "Epoch 63/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8769 - loss: 0.2611 - val_accuracy: 0.8826 - val_loss: 0.2792\n",
      "Epoch 64/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8778 - loss: 0.2611 - val_accuracy: 0.8769 - val_loss: 0.2800\n",
      "Epoch 65/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8769 - loss: 0.2608 - val_accuracy: 0.8788 - val_loss: 0.2797\n",
      "Epoch 66/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8787 - loss: 0.2606 - val_accuracy: 0.8788 - val_loss: 0.2793\n",
      "Epoch 67/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8778 - loss: 0.2606 - val_accuracy: 0.8788 - val_loss: 0.2802\n",
      "Epoch 68/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8759 - loss: 0.2610 - val_accuracy: 0.8788 - val_loss: 0.2789\n",
      "Epoch 69/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8778 - loss: 0.2605 - val_accuracy: 0.8826 - val_loss: 0.2791\n",
      "Epoch 70/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8778 - loss: 0.2594 - val_accuracy: 0.8788 - val_loss: 0.2791\n",
      "Epoch 71/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8769 - loss: 0.2594 - val_accuracy: 0.8769 - val_loss: 0.2799\n",
      "Epoch 72/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8797 - loss: 0.2593 - val_accuracy: 0.8769 - val_loss: 0.2798\n",
      "Epoch 73/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8787 - loss: 0.2589 - val_accuracy: 0.8750 - val_loss: 0.2794\n",
      "Epoch 74/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8787 - loss: 0.2591 - val_accuracy: 0.8750 - val_loss: 0.2796\n",
      "Epoch 75/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8778 - loss: 0.2584 - val_accuracy: 0.8750 - val_loss: 0.2800\n",
      "Epoch 76/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8815 - loss: 0.2584 - val_accuracy: 0.8807 - val_loss: 0.2793\n",
      "Epoch 77/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8778 - loss: 0.2580 - val_accuracy: 0.8769 - val_loss: 0.2791\n",
      "Epoch 78/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8797 - loss: 0.2579 - val_accuracy: 0.8731 - val_loss: 0.2799\n",
      "Epoch 79/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8834 - loss: 0.2575 - val_accuracy: 0.8769 - val_loss: 0.2801\n",
      "Epoch 80/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8806 - loss: 0.2569 - val_accuracy: 0.8769 - val_loss: 0.2795\n",
      "Epoch 81/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8797 - loss: 0.2571 - val_accuracy: 0.8731 - val_loss: 0.2806\n",
      "Epoch 82/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8825 - loss: 0.2569 - val_accuracy: 0.8769 - val_loss: 0.2809\n",
      "Epoch 83/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8815 - loss: 0.2562 - val_accuracy: 0.8769 - val_loss: 0.2810\n",
      "Epoch 84/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8853 - loss: 0.2566 - val_accuracy: 0.8788 - val_loss: 0.2799\n",
      "Epoch 85/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8778 - loss: 0.2561 - val_accuracy: 0.8769 - val_loss: 0.2797\n",
      "Epoch 86/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8797 - loss: 0.2559 - val_accuracy: 0.8788 - val_loss: 0.2796\n",
      "Epoch 87/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8787 - loss: 0.2558 - val_accuracy: 0.8769 - val_loss: 0.2807\n",
      "Epoch 88/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8797 - loss: 0.2557 - val_accuracy: 0.8769 - val_loss: 0.2801\n",
      "Epoch 89/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8825 - loss: 0.2549 - val_accuracy: 0.8769 - val_loss: 0.2813\n",
      "Epoch 90/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8843 - loss: 0.2559 - val_accuracy: 0.8769 - val_loss: 0.2806\n",
      "Epoch 91/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8834 - loss: 0.2550 - val_accuracy: 0.8769 - val_loss: 0.2808\n",
      "Epoch 92/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8797 - loss: 0.2551 - val_accuracy: 0.8807 - val_loss: 0.2816\n",
      "Epoch 93/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8787 - loss: 0.2542 - val_accuracy: 0.8769 - val_loss: 0.2808\n",
      "Epoch 94/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8806 - loss: 0.2546 - val_accuracy: 0.8788 - val_loss: 0.2804\n",
      "Epoch 95/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8815 - loss: 0.2542 - val_accuracy: 0.8769 - val_loss: 0.2808\n",
      "Epoch 96/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8834 - loss: 0.2538 - val_accuracy: 0.8769 - val_loss: 0.2809\n",
      "Epoch 97/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8797 - loss: 0.2536 - val_accuracy: 0.8769 - val_loss: 0.2807\n",
      "Epoch 98/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8834 - loss: 0.2539 - val_accuracy: 0.8769 - val_loss: 0.2812\n",
      "Epoch 99/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8797 - loss: 0.2536 - val_accuracy: 0.8769 - val_loss: 0.2814\n",
      "Epoch 100/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8797 - loss: 0.2537 - val_accuracy: 0.8769 - val_loss: 0.2814\n"
     ]
    }
   ],
   "source": [
    "Model_history= classifier.fit(X_train, y_train, validation_split=0.33,batch_size= 10, epochs= 100,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95887bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m40\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m30\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">230</span> (924.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m230\u001b[0m (924.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">76</span> (304.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m76\u001b[0m (304.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">154</span> (620.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m154\u001b[0m (620.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "625a8c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.98108864e-01],\n",
       "       [9.88164604e-01],\n",
       "       [9.68948901e-01],\n",
       "       [3.15274298e-01],\n",
       "       [9.87193704e-01],\n",
       "       [7.52355278e-01],\n",
       "       [9.95961607e-01],\n",
       "       [4.69109625e-01],\n",
       "       [5.04738502e-02],\n",
       "       [1.13080502e-01],\n",
       "       [4.85434175e-01],\n",
       "       [8.32697153e-01],\n",
       "       [3.98338169e-01],\n",
       "       [9.80146170e-01],\n",
       "       [9.97742474e-01],\n",
       "       [1.68659106e-01],\n",
       "       [9.20359075e-01],\n",
       "       [7.79991567e-01],\n",
       "       [8.02685246e-02],\n",
       "       [9.59377643e-03],\n",
       "       [9.87639785e-01],\n",
       "       [9.87026215e-01],\n",
       "       [9.72739041e-01],\n",
       "       [9.54310358e-01],\n",
       "       [1.80367216e-01],\n",
       "       [7.63894677e-01],\n",
       "       [9.88172829e-01],\n",
       "       [5.81151014e-03],\n",
       "       [6.06630921e-01],\n",
       "       [9.98373449e-01],\n",
       "       [8.53769541e-01],\n",
       "       [9.80707347e-01],\n",
       "       [1.20250415e-02],\n",
       "       [1.73883244e-01],\n",
       "       [1.00915115e-02],\n",
       "       [1.11791473e-04],\n",
       "       [9.98472273e-01],\n",
       "       [1.48801893e-01],\n",
       "       [9.87658978e-01],\n",
       "       [5.15835127e-03],\n",
       "       [5.32139063e-01],\n",
       "       [1.79995969e-01],\n",
       "       [9.98774111e-01],\n",
       "       [7.02524092e-03],\n",
       "       [4.00005691e-02],\n",
       "       [8.26700807e-01],\n",
       "       [2.59120107e-01],\n",
       "       [9.22863007e-01],\n",
       "       [8.17358375e-01],\n",
       "       [1.87129815e-04],\n",
       "       [5.94980929e-06],\n",
       "       [7.97051430e-01],\n",
       "       [4.44211625e-03],\n",
       "       [1.15998611e-02],\n",
       "       [3.98127526e-01],\n",
       "       [5.07593989e-01],\n",
       "       [2.75262922e-01],\n",
       "       [8.53941124e-03],\n",
       "       [9.87763047e-01],\n",
       "       [7.49288023e-01],\n",
       "       [3.68533731e-01],\n",
       "       [1.45576507e-01],\n",
       "       [9.97741222e-01],\n",
       "       [9.89204228e-01],\n",
       "       [8.95396113e-01],\n",
       "       [4.45612147e-02],\n",
       "       [3.61494645e-02],\n",
       "       [6.87978044e-02],\n",
       "       [5.05351007e-01],\n",
       "       [4.48224209e-02],\n",
       "       [9.38917160e-01],\n",
       "       [4.80365843e-01],\n",
       "       [4.78717964e-03],\n",
       "       [9.21375275e-01],\n",
       "       [9.98640358e-01],\n",
       "       [7.19604967e-03],\n",
       "       [8.04280758e-01],\n",
       "       [9.33019698e-01],\n",
       "       [9.98435616e-01],\n",
       "       [9.86443579e-01],\n",
       "       [6.57922402e-02],\n",
       "       [1.46497833e-03],\n",
       "       [1.84318498e-02],\n",
       "       [9.74984229e-01],\n",
       "       [9.28196669e-01],\n",
       "       [9.98338342e-01],\n",
       "       [7.23004103e-01],\n",
       "       [8.97326946e-01],\n",
       "       [6.53968900e-02],\n",
       "       [2.13713814e-02],\n",
       "       [1.66412629e-02],\n",
       "       [9.01284039e-01],\n",
       "       [5.32463074e-01],\n",
       "       [4.92037361e-05],\n",
       "       [1.58423465e-03],\n",
       "       [2.33194344e-02],\n",
       "       [8.19640100e-01],\n",
       "       [4.42181796e-01],\n",
       "       [9.24584746e-01],\n",
       "       [6.02328539e-01],\n",
       "       [5.22266999e-02],\n",
       "       [3.84143144e-02],\n",
       "       [6.88797593e-01],\n",
       "       [9.88522768e-01],\n",
       "       [9.80460048e-01],\n",
       "       [1.98514778e-02],\n",
       "       [9.96990144e-01],\n",
       "       [7.19956100e-01],\n",
       "       [9.64972138e-01],\n",
       "       [2.15747312e-01],\n",
       "       [9.08643659e-03],\n",
       "       [1.74828172e-02],\n",
       "       [3.07674147e-03],\n",
       "       [5.90430081e-01],\n",
       "       [1.55797862e-02],\n",
       "       [9.78693599e-04],\n",
       "       [7.33689442e-02],\n",
       "       [1.97613781e-06],\n",
       "       [9.79753554e-01],\n",
       "       [6.72578216e-01],\n",
       "       [1.11715542e-03],\n",
       "       [9.97362673e-01],\n",
       "       [9.70237076e-01],\n",
       "       [9.99117255e-01],\n",
       "       [3.22123021e-01],\n",
       "       [1.23177776e-02],\n",
       "       [9.83340323e-01],\n",
       "       [9.82998848e-01],\n",
       "       [9.83850598e-01],\n",
       "       [6.09292872e-02],\n",
       "       [7.98653424e-01],\n",
       "       [9.98525202e-01],\n",
       "       [4.69748862e-02],\n",
       "       [7.14203417e-01],\n",
       "       [7.11852859e-04],\n",
       "       [8.83364201e-01],\n",
       "       [9.70989645e-01],\n",
       "       [3.75510869e-03],\n",
       "       [8.74801949e-02],\n",
       "       [2.18832821e-01],\n",
       "       [2.15874091e-01],\n",
       "       [1.70238659e-01],\n",
       "       [7.91383386e-01],\n",
       "       [6.00169659e-01],\n",
       "       [4.82956529e-01],\n",
       "       [4.48587924e-01],\n",
       "       [3.97113681e-01],\n",
       "       [9.61184144e-01],\n",
       "       [2.40307953e-02],\n",
       "       [7.16797590e-01],\n",
       "       [3.10637206e-01],\n",
       "       [9.51036870e-01],\n",
       "       [6.22259557e-01],\n",
       "       [7.64266133e-01],\n",
       "       [2.41436753e-02],\n",
       "       [4.50157700e-03],\n",
       "       [8.17364431e-04],\n",
       "       [6.14636540e-01],\n",
       "       [6.84051514e-01],\n",
       "       [4.51225461e-03],\n",
       "       [9.79107082e-01],\n",
       "       [1.70416868e-04],\n",
       "       [9.94375229e-01],\n",
       "       [1.11044176e-01],\n",
       "       [8.08538049e-02],\n",
       "       [9.20746148e-01],\n",
       "       [6.00993186e-02],\n",
       "       [9.68613863e-01],\n",
       "       [9.17660534e-01],\n",
       "       [3.70509028e-01],\n",
       "       [9.27300096e-01],\n",
       "       [8.93390179e-02],\n",
       "       [9.99131799e-01],\n",
       "       [7.35259175e-01],\n",
       "       [2.51122372e-04],\n",
       "       [9.95158970e-01],\n",
       "       [9.81717110e-01],\n",
       "       [9.01401579e-01],\n",
       "       [9.14122820e-01],\n",
       "       [9.83431458e-01],\n",
       "       [1.28060997e-01],\n",
       "       [6.04581311e-02],\n",
       "       [2.95178425e-02],\n",
       "       [9.57828999e-01],\n",
       "       [7.04671264e-01],\n",
       "       [9.85399842e-01],\n",
       "       [8.44545662e-04],\n",
       "       [7.57899463e-01],\n",
       "       [9.42686081e-01],\n",
       "       [5.70026459e-03],\n",
       "       [1.66557189e-02],\n",
       "       [1.60762087e-01],\n",
       "       [9.84437227e-01],\n",
       "       [2.88640969e-02],\n",
       "       [3.14948295e-04],\n",
       "       [1.92909583e-01],\n",
       "       [9.61769223e-01],\n",
       "       [1.89926386e-01],\n",
       "       [9.99988854e-01],\n",
       "       [1.96700003e-02],\n",
       "       [8.55359342e-03],\n",
       "       [9.99725938e-01],\n",
       "       [5.19492984e-01],\n",
       "       [1.20907854e-02],\n",
       "       [1.88304912e-02],\n",
       "       [8.02200079e-01],\n",
       "       [5.13101578e-01],\n",
       "       [9.78600800e-01],\n",
       "       [9.98509407e-01],\n",
       "       [9.97639716e-01],\n",
       "       [5.00273347e-01],\n",
       "       [7.42392265e-04],\n",
       "       [2.51755983e-01],\n",
       "       [4.71454039e-02],\n",
       "       [4.66104090e-01],\n",
       "       [7.42218830e-03],\n",
       "       [1.64581969e-01],\n",
       "       [6.70429587e-01],\n",
       "       [9.92734909e-01],\n",
       "       [8.71340275e-01],\n",
       "       [9.62548137e-01],\n",
       "       [4.56365012e-03],\n",
       "       [9.78105068e-01],\n",
       "       [1.63734004e-01],\n",
       "       [9.13779676e-01],\n",
       "       [3.83212715e-02],\n",
       "       [2.26996809e-01],\n",
       "       [2.69146194e-03],\n",
       "       [9.61598635e-01],\n",
       "       [3.20221722e-01],\n",
       "       [8.85632704e-04],\n",
       "       [9.42576468e-01],\n",
       "       [9.93369579e-01],\n",
       "       [8.92505050e-01],\n",
       "       [3.51159364e-01],\n",
       "       [8.84594321e-01],\n",
       "       [5.09686410e-01],\n",
       "       [7.88881660e-01],\n",
       "       [8.75803053e-01],\n",
       "       [8.38633895e-01],\n",
       "       [9.98601377e-01],\n",
       "       [5.91389462e-03],\n",
       "       [5.47804475e-01],\n",
       "       [3.32010865e-01],\n",
       "       [1.71026867e-02],\n",
       "       [2.48597711e-01],\n",
       "       [9.55515504e-01],\n",
       "       [4.93773492e-03],\n",
       "       [7.47135520e-01],\n",
       "       [7.54441619e-01],\n",
       "       [1.22750394e-01],\n",
       "       [3.93637791e-02],\n",
       "       [8.03396523e-01],\n",
       "       [2.47323513e-03],\n",
       "       [7.97272623e-01],\n",
       "       [3.04673966e-02],\n",
       "       [7.00486198e-05],\n",
       "       [9.88873959e-01],\n",
       "       [4.46682349e-02],\n",
       "       [2.04504863e-03],\n",
       "       [9.34707522e-01],\n",
       "       [9.98989761e-01],\n",
       "       [7.17046484e-02],\n",
       "       [9.97360408e-01],\n",
       "       [9.97876883e-01],\n",
       "       [6.28628244e-04],\n",
       "       [8.91057849e-01],\n",
       "       [4.68466803e-02],\n",
       "       [1.42958239e-02],\n",
       "       [6.46487236e-01],\n",
       "       [6.36884291e-03],\n",
       "       [1.95468834e-04],\n",
       "       [8.06553476e-03],\n",
       "       [4.00900608e-03],\n",
       "       [9.22523737e-01],\n",
       "       [9.70909476e-01],\n",
       "       [8.36573599e-05],\n",
       "       [1.10861927e-03],\n",
       "       [2.50191331e-01],\n",
       "       [8.66162062e-01],\n",
       "       [1.66927148e-02],\n",
       "       [2.76957333e-01],\n",
       "       [3.36845918e-03],\n",
       "       [3.18177394e-03],\n",
       "       [9.99112904e-01],\n",
       "       [9.94519949e-01],\n",
       "       [9.09357727e-01],\n",
       "       [4.15450544e-04],\n",
       "       [8.46665427e-02],\n",
       "       [9.66680527e-01],\n",
       "       [5.24030589e-02],\n",
       "       [1.09435723e-03],\n",
       "       [2.41530128e-02],\n",
       "       [2.18243562e-02],\n",
       "       [9.97505069e-01],\n",
       "       [9.59481359e-01],\n",
       "       [9.18892860e-01],\n",
       "       [1.59688994e-01],\n",
       "       [9.93501306e-01],\n",
       "       [9.88911629e-01],\n",
       "       [2.59521287e-02],\n",
       "       [2.09578294e-02],\n",
       "       [3.65994602e-01],\n",
       "       [9.88430560e-01],\n",
       "       [1.95280179e-01],\n",
       "       [1.23335626e-02],\n",
       "       [5.81432767e-02],\n",
       "       [1.58395041e-02],\n",
       "       [9.99691784e-01],\n",
       "       [9.84872758e-01],\n",
       "       [1.20291589e-02],\n",
       "       [7.23608769e-04],\n",
       "       [1.69439048e-01],\n",
       "       [9.98347461e-01],\n",
       "       [8.34584415e-01],\n",
       "       [9.44163322e-01],\n",
       "       [3.74176763e-02],\n",
       "       [9.82630014e-01],\n",
       "       [1.35409549e-01],\n",
       "       [3.12740088e-01],\n",
       "       [9.98393595e-01],\n",
       "       [5.59839047e-02],\n",
       "       [6.19280562e-02],\n",
       "       [9.34366226e-01],\n",
       "       [9.94055152e-01],\n",
       "       [8.04701567e-01],\n",
       "       [4.74307453e-03],\n",
       "       [8.78595829e-01],\n",
       "       [8.00247729e-01],\n",
       "       [9.85983789e-01],\n",
       "       [9.79258239e-01],\n",
       "       [9.09415912e-03],\n",
       "       [9.99497175e-01],\n",
       "       [9.97445166e-01],\n",
       "       [8.05395597e-04],\n",
       "       [4.13559586e-01],\n",
       "       [4.38072443e-01],\n",
       "       [9.43051338e-01],\n",
       "       [2.39853859e-02],\n",
       "       [9.95912671e-01],\n",
       "       [6.23444887e-03],\n",
       "       [4.30412769e-01],\n",
       "       [9.70056713e-01],\n",
       "       [1.00782491e-01],\n",
       "       [1.93627187e-04],\n",
       "       [8.32511842e-01],\n",
       "       [1.56168059e-01],\n",
       "       [7.73956537e-01],\n",
       "       [3.29072447e-03],\n",
       "       [4.69964802e-01],\n",
       "       [7.05190420e-01],\n",
       "       [2.23067030e-02],\n",
       "       [3.23157519e-01],\n",
       "       [9.99089301e-01],\n",
       "       [9.28018749e-01],\n",
       "       [3.09004236e-06],\n",
       "       [3.46611254e-04],\n",
       "       [3.10995758e-01],\n",
       "       [9.95493948e-01],\n",
       "       [9.97377515e-01],\n",
       "       [9.95299935e-01],\n",
       "       [8.73109162e-01],\n",
       "       [6.31943569e-02],\n",
       "       [3.67951423e-01],\n",
       "       [9.98942137e-01],\n",
       "       [3.99299106e-03],\n",
       "       [1.14393141e-02],\n",
       "       [9.22723860e-03],\n",
       "       [6.43802283e-04],\n",
       "       [1.45782724e-01],\n",
       "       [8.40406537e-01],\n",
       "       [2.53407005e-03],\n",
       "       [7.53737018e-02],\n",
       "       [9.94090974e-01],\n",
       "       [7.81797647e-01],\n",
       "       [8.74298811e-01],\n",
       "       [2.12366300e-04],\n",
       "       [9.87771749e-01],\n",
       "       [6.19867742e-01],\n",
       "       [9.89750683e-01],\n",
       "       [7.09438443e-01],\n",
       "       [2.10105511e-03],\n",
       "       [7.39706397e-01],\n",
       "       [7.79338717e-01],\n",
       "       [5.73891774e-03],\n",
       "       [5.61190486e-01],\n",
       "       [9.74296570e-01],\n",
       "       [9.99738812e-01],\n",
       "       [2.24874564e-03],\n",
       "       [2.42985576e-01],\n",
       "       [5.57812572e-01],\n",
       "       [5.97600698e-01],\n",
       "       [1.13112910e-03],\n",
       "       [9.14921284e-01],\n",
       "       [1.92556661e-02],\n",
       "       [8.01813960e-01],\n",
       "       [9.67359543e-01],\n",
       "       [1.35773598e-05],\n",
       "       [9.94882047e-01],\n",
       "       [5.33222873e-03]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5007a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = [1 if y>=0.5 else 0 for y in y_pred]\n",
    "print(y_pred2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4f810cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2 = [1 if y>=0.5 else 0 for y in y_pred]\n",
    "y_pred2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "934e56bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f39aaed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8775"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c37d9326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8775 - loss: 0.2680 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "Loss,Accuracy= classifier.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6869d0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = classifier.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9490e596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS:0.2680\n",
      "Accuracy:87.75%\n"
     ]
    }
   ],
   "source": [
    "print(f\"LOSS:{loss:.4f}\")\n",
    "print(f\"Accuracy:{Accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5ed6a1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.87      0.88       204\n",
      "         1.0       0.87      0.89      0.88       196\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.88      0.88      0.88       400\n",
      "weighted avg       0.88      0.88      0.88       400\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[177  27]\n",
      " [ 22 174]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# It's good practice to get the raw probabilities from the model first\n",
    "y_pred_probabilities = classifier.predict(X_test)\n",
    "\n",
    "# IMPORTANT: Convert probabilities into final 0 or 1 predictions\n",
    "y_pred_final = (y_pred_probabilities > 0.5).astype(int)\n",
    "\n",
    "# Now, use the final binary predictions in your reports\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_final))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_final)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efce89d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-genAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
